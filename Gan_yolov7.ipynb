{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Phatdat01/GAN/blob/main/Gan_yolov7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9qlwF1UW4qV_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "769250c9-9b33-4799-e3e5-644647f4006a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-WJU-xx_BYtV8oQ0KYAaHhx38RpJw1VI\n",
            "To: /content/vegetadata.rar\n",
            "100% 130M/130M [00:04<00:00, 29.7MB/s]\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting split-folders\n",
            "  Downloading split_folders-0.5.1-py3-none-any.whl (8.4 kB)\n",
            "Installing collected packages: split-folders\n",
            "Successfully installed split-folders-0.5.1\n",
            "Cloning into 'yolov7'...\n",
            "remote: Enumerating objects: 998, done.\u001b[K\n",
            "remote: Total 998 (delta 0), reused 0 (delta 0), pack-reused 998\u001b[K\n",
            "Receiving objects: 100% (998/998), 69.77 MiB | 37.53 MiB/s, done.\n",
            "Resolving deltas: 100% (465/465), done.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting patool\n",
            "  Downloading patool-1.12-py2.py3-none-any.whl (77 kB)\n",
            "\u001b[K     |████████████████████████████████| 77 kB 6.7 MB/s \n",
            "\u001b[?25hInstalling collected packages: patool\n",
            "Successfully installed patool-1.12\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting wandb\n",
            "  Downloading wandb-0.13.5-py2.py3-none-any.whl (1.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.9 MB 26.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n",
            "Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n",
            "Collecting pathtools\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "Collecting setproctitle\n",
            "  Downloading setproctitle-1.3.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n",
            "Collecting shortuuid>=0.5.0\n",
            "  Downloading shortuuid-1.0.11-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from wandb) (57.4.0)\n",
            "Collecting docker-pycreds>=0.4.0\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (6.0)\n",
            "Collecting GitPython>=1.0.0\n",
            "  Downloading GitPython-3.1.29-py3-none-any.whl (182 kB)\n",
            "\u001b[K     |████████████████████████████████| 182 kB 70.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf!=4.0.*,!=4.21.0,<5,>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.19.6)\n",
            "Collecting sentry-sdk>=1.0.0\n",
            "  Downloading sentry_sdk-1.11.0-py2.py3-none-any.whl (168 kB)\n",
            "\u001b[K     |████████████████████████████████| 168 kB 72.5 MB/s \n",
            "\u001b[?25hCollecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 2.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (4.1.1)\n",
            "Collecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2022.9.24)\n",
            "Collecting sentry-sdk>=1.0.0\n",
            "  Downloading sentry_sdk-1.10.1-py2.py3-none-any.whl (166 kB)\n",
            "\u001b[K     |████████████████████████████████| 166 kB 70.5 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.10.0-py2.py3-none-any.whl (166 kB)\n",
            "\u001b[K     |████████████████████████████████| 166 kB 77.1 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.10-py2.py3-none-any.whl (162 kB)\n",
            "\u001b[K     |████████████████████████████████| 162 kB 29.3 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.9-py2.py3-none-any.whl (162 kB)\n",
            "\u001b[K     |████████████████████████████████| 162 kB 61.7 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.8-py2.py3-none-any.whl (158 kB)\n",
            "\u001b[K     |████████████████████████████████| 158 kB 80.5 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.7-py2.py3-none-any.whl (157 kB)\n",
            "\u001b[K     |████████████████████████████████| 157 kB 65.6 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.6-py2.py3-none-any.whl (157 kB)\n",
            "\u001b[K     |████████████████████████████████| 157 kB 78.9 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.5-py2.py3-none-any.whl (157 kB)\n",
            "\u001b[K     |████████████████████████████████| 157 kB 77.8 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.4-py2.py3-none-any.whl (157 kB)\n",
            "\u001b[K     |████████████████████████████████| 157 kB 80.8 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.3-py2.py3-none-any.whl (157 kB)\n",
            "\u001b[K     |████████████████████████████████| 157 kB 77.6 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.2-py2.py3-none-any.whl (157 kB)\n",
            "\u001b[K     |████████████████████████████████| 157 kB 78.4 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.1-py2.py3-none-any.whl (157 kB)\n",
            "\u001b[K     |████████████████████████████████| 157 kB 76.7 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.0-py2.py3-none-any.whl (156 kB)\n",
            "\u001b[K     |████████████████████████████████| 156 kB 77.3 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pathtools\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8806 sha256=a3e200a5c67654d58f627be71e434a20b213a26368f8b8de90c9d13dcbe74359\n",
            "  Stored in directory: /root/.cache/pip/wheels/3e/31/09/fa59cef12cdcfecc627b3d24273699f390e71828921b2cbba2\n",
            "Successfully built pathtools\n",
            "Installing collected packages: smmap, gitdb, shortuuid, setproctitle, sentry-sdk, pathtools, GitPython, docker-pycreds, wandb\n",
            "Successfully installed GitPython-3.1.29 docker-pycreds-0.4.0 gitdb-4.0.9 pathtools-0.1.2 sentry-sdk-1.9.0 setproctitle-1.3.2 shortuuid-1.0.11 smmap-5.0.0 wandb-0.13.5\n",
            "/content/yolov7\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 4)) (3.2.2)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 5)) (1.21.6)\n",
            "Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 6)) (4.6.0.66)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 7)) (7.1.2)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 8)) (6.0)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 9)) (2.23.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 10)) (1.7.3)\n",
            "Requirement already satisfied: torch!=1.12.0,>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 11)) (1.12.1+cu113)\n",
            "Requirement already satisfied: torchvision!=0.13.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 12)) (0.13.1+cu113)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 13)) (4.64.1)\n",
            "Requirement already satisfied: protobuf<4.21.3 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 14)) (3.19.6)\n",
            "Requirement already satisfied: tensorboard>=2.4.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 17)) (2.9.1)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 21)) (1.3.5)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 22)) (0.11.2)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 34)) (7.9.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 35)) (5.4.8)\n",
            "Collecting thop\n",
            "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (1.4.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (0.11.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.23.0->-r requirements.txt (line 9)) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.23.0->-r requirements.txt (line 9)) (2022.9.24)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.23.0->-r requirements.txt (line 9)) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.23.0->-r requirements.txt (line 9)) (1.24.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (4.1.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (1.8.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (0.38.3)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (1.0.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (57.4.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (0.6.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (3.4.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (2.14.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (0.4.6)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (1.3.0)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (1.50.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.1.4->-r requirements.txt (line 21)) (2022.6)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 17)) (5.2.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 17)) (0.2.8)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 17)) (1.15.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 17)) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.4.1->-r requirements.txt (line 17)) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=2.4.1->-r requirements.txt (line 17)) (4.13.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.4.1->-r requirements.txt (line 17)) (3.10.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 17)) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.4.1->-r requirements.txt (line 17)) (3.2.2)\n",
            "Collecting jedi>=0.10\n",
            "  Downloading jedi-0.18.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 35.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->-r requirements.txt (line 34)) (2.6.1)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython->-r requirements.txt (line 34)) (5.1.1)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython->-r requirements.txt (line 34)) (4.8.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->-r requirements.txt (line 34)) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->-r requirements.txt (line 34)) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from ipython->-r requirements.txt (line 34)) (2.0.10)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.7/dist-packages (from ipython->-r requirements.txt (line 34)) (0.2.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from jedi>=0.10->ipython->-r requirements.txt (line 34)) (0.8.3)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython->-r requirements.txt (line 34)) (0.2.5)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython->-r requirements.txt (line 34)) (0.7.0)\n",
            "Installing collected packages: jedi, thop\n",
            "Successfully installed jedi-0.18.1 thop-0.1.1.post2209072238\n",
            "--2022-11-20 04:53:34--  https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7.pt\n",
            "Resolving github.com (github.com)... 140.82.112.3\n",
            "Connecting to github.com (github.com)|140.82.112.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/511187726/b0243edf-9fb0-4337-95e1-42555f1b37cf?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20221120%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20221120T045334Z&X-Amz-Expires=300&X-Amz-Signature=72fe25ea9d1ce5a970f68f1ac8a0f5bee16ea791107a22540716a8885b5b2475&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=511187726&response-content-disposition=attachment%3B%20filename%3Dyolov7.pt&response-content-type=application%2Foctet-stream [following]\n",
            "--2022-11-20 04:53:34--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/511187726/b0243edf-9fb0-4337-95e1-42555f1b37cf?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20221120%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20221120T045334Z&X-Amz-Expires=300&X-Amz-Signature=72fe25ea9d1ce5a970f68f1ac8a0f5bee16ea791107a22540716a8885b5b2475&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=511187726&response-content-disposition=attachment%3B%20filename%3Dyolov7.pt&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 75587165 (72M) [application/octet-stream]\n",
            "Saving to: ‘yolov7.pt’\n",
            "\n",
            "yolov7.pt           100%[===================>]  72.08M   147MB/s    in 0.5s    \n",
            "\n",
            "2022-11-20 04:53:35 (147 MB/s) - ‘yolov7.pt’ saved [75587165/75587165]\n",
            "\n",
            "--2022-11-20 04:53:35--  https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7-tiny.pt\n",
            "Resolving github.com (github.com)... 140.82.112.3\n",
            "Connecting to github.com (github.com)|140.82.112.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/511187726/ba7d01ee-125a-4134-8864-fa1abcbf94d5?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20221120%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20221120T045335Z&X-Amz-Expires=300&X-Amz-Signature=e2236f07df0a990b245d3d43d59c4d526f0341fe2677c3f294b502a9aad62f74&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=511187726&response-content-disposition=attachment%3B%20filename%3Dyolov7-tiny.pt&response-content-type=application%2Foctet-stream [following]\n",
            "--2022-11-20 04:53:35--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/511187726/ba7d01ee-125a-4134-8864-fa1abcbf94d5?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20221120%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20221120T045335Z&X-Amz-Expires=300&X-Amz-Signature=e2236f07df0a990b245d3d43d59c4d526f0341fe2677c3f294b502a9aad62f74&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=511187726&response-content-disposition=attachment%3B%20filename%3Dyolov7-tiny.pt&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 12639769 (12M) [application/octet-stream]\n",
            "Saving to: ‘yolov7-tiny.pt’\n",
            "\n",
            "yolov7-tiny.pt      100%[===================>]  12.05M  --.-KB/s    in 0.06s   \n",
            "\n",
            "2022-11-20 04:53:35 (206 MB/s) - ‘yolov7-tiny.pt’ saved [12639769/12639769]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "%cd /content\n",
        "!gdown 1-WJU-xx_BYtV8oQ0KYAaHhx38RpJw1VI\n",
        "!pip install split-folders\n",
        "!git clone https://github.com/WongKinYiu/yolov7.git\n",
        "!pip install patool\n",
        "!pip install wandb\n",
        "%cd yolov7\n",
        "!pip install -r requirements.txt\n",
        "!wget https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7.pt\n",
        "!wget https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7-tiny.pt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content\n",
        "import patoolib\n",
        "patoolib.extract_archive(\"vegetadata.rar\", outdir=\".\")\n",
        "!rm /content/vegetadata.rar"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6s71WI-A9fSy",
        "outputId": "223ab06f-20ff-4fd6-88c0-d0e09cc6453d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "patool: Extracting vegetadata.rar ...\n",
            "patool: running /usr/bin/unrar x -- /content/vegetadata.rar\n",
            "patool:     with cwd='.'\n",
            "patool: ... vegetadata.rar extracted to `.'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## label: \n",
        "\"\"\"\n",
        "['songoku','luffy', 'vegito', 'ichigo', 'tsuna', 'naruto', 'vegeta', 'gogeta', 'sasuke', 'gohan', 'zoro', 'sanji', 'kakashi', 'sakura', 'hinata', 'trunk', 'nami', 'gintama', 'itachi', 'usop']\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "ECM1zfxAFFuz",
        "outputId": "4cee510f-f782-41ba-dab4-1672db1c9c39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n['songoku','luffy', 'vegito', 'ichigo', 'tsuna', 'naruto', 'vegeta', 'gogeta', 'sasuke', 'gohan', 'zoro', 'sanji', 'kakashi', 'sakura', 'hinata', 'trunk', 'nami', 'gintama', 'itachi', 'usop']\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tiny\n",
        "%cd /content/yolov7\n",
        "!python train.py --epochs 10 --workers 4 --device 0 --batch-size 32 \\\n",
        "--data data/coco.yaml --img 640 640 --cfg cfg/training/yolov7-tiny.yaml \\\n",
        "--weights 'yolov7-tiny.pt' --name tinyModel --hyp data/hyp.scratch.tiny.yaml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "knxanUeICfS6",
        "outputId": "29e0a83b-ecd3-49e0-eb0b-c618e491e4f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/yolov7\n",
            "YOLOR 🚀 v0.1-115-g072f76c torch 1.12.1+cu113 CUDA:0 (Tesla T4, 15109.75MB)\n",
            "\n",
            "Namespace(adam=False, artifact_alias='latest', batch_size=32, bbox_interval=-1, bucket='', cache_images=False, cfg='cfg/training/yolov7-tiny.yaml', data='data/coco.yaml', device='0', entity=None, epochs=10, evolve=False, exist_ok=False, freeze=[0], global_rank=-1, hyp='data/hyp.scratch.tiny.yaml', image_weights=False, img_size=[640, 640], label_smoothing=0.0, linear_lr=False, local_rank=-1, multi_scale=False, name='tinyModel', noautoanchor=False, nosave=False, notest=False, project='runs/train', quad=False, rect=False, resume=False, save_dir='runs/train/tinyModel5', save_period=-1, single_cls=False, sync_bn=False, total_batch_size=32, upload_dataset=False, v5_metric=False, weights='yolov7-tiny.pt', workers=4, world_size=1)\n",
            "\u001b[34m\u001b[1mtensorboard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.05, copy_paste=0.0, paste_in=0.05, loss_ota=1\n",
            "\u001b[34m\u001b[1mwandb: \u001b[0mInstall Weights & Biases for YOLOR logging with 'pip install wandb' (recommended)\n",
            "Overriding model.yaml nc=80 with nc=20\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1       928  models.common.Conv                      [3, 32, 3, 2, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            "  2                -1  1      2112  models.common.Conv                      [64, 32, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            "  3                -2  1      2112  models.common.Conv                      [64, 32, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            "  4                -1  1      9280  models.common.Conv                      [32, 32, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            "  5                -1  1      9280  models.common.Conv                      [32, 32, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            "  6  [-1, -2, -3, -4]  1         0  models.common.Concat                    [1]                           \n",
            "  7                -1  1      8320  models.common.Conv                      [128, 64, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            "  8                -1  1         0  models.common.MP                        []                            \n",
            "  9                -1  1      4224  models.common.Conv                      [64, 64, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 10                -2  1      4224  models.common.Conv                      [64, 64, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 11                -1  1     36992  models.common.Conv                      [64, 64, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 12                -1  1     36992  models.common.Conv                      [64, 64, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 13  [-1, -2, -3, -4]  1         0  models.common.Concat                    [1]                           \n",
            " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 15                -1  1         0  models.common.MP                        []                            \n",
            " 16                -1  1     16640  models.common.Conv                      [128, 128, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 17                -2  1     16640  models.common.Conv                      [128, 128, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 19                -1  1    147712  models.common.Conv                      [128, 128, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 20  [-1, -2, -3, -4]  1         0  models.common.Concat                    [1]                           \n",
            " 21                -1  1    131584  models.common.Conv                      [512, 256, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 22                -1  1         0  models.common.MP                        []                            \n",
            " 23                -1  1     66048  models.common.Conv                      [256, 256, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 24                -2  1     66048  models.common.Conv                      [256, 256, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 25                -1  1    590336  models.common.Conv                      [256, 256, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 26                -1  1    590336  models.common.Conv                      [256, 256, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 27  [-1, -2, -3, -4]  1         0  models.common.Concat                    [1]                           \n",
            " 28                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 29                -1  1    131584  models.common.Conv                      [512, 256, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 30                -2  1    131584  models.common.Conv                      [512, 256, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 31                -1  1         0  models.common.SP                        [5]                           \n",
            " 32                -2  1         0  models.common.SP                        [9]                           \n",
            " 33                -3  1         0  models.common.SP                        [13]                          \n",
            " 34  [-1, -2, -3, -4]  1         0  models.common.Concat                    [1]                           \n",
            " 35                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 36          [-1, -7]  1         0  models.common.Concat                    [1]                           \n",
            " 37                -1  1    131584  models.common.Conv                      [512, 256, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 38                -1  1     33024  models.common.Conv                      [256, 128, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 39                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 40                21  1     33024  models.common.Conv                      [256, 128, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 41          [-1, -2]  1         0  models.common.Concat                    [1]                           \n",
            " 42                -1  1     16512  models.common.Conv                      [256, 64, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 43                -2  1     16512  models.common.Conv                      [256, 64, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 44                -1  1     36992  models.common.Conv                      [64, 64, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 45                -1  1     36992  models.common.Conv                      [64, 64, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 46  [-1, -2, -3, -4]  1         0  models.common.Concat                    [1]                           \n",
            " 47                -1  1     33024  models.common.Conv                      [256, 128, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 48                -1  1      8320  models.common.Conv                      [128, 64, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 49                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 50                14  1      8320  models.common.Conv                      [128, 64, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 51          [-1, -2]  1         0  models.common.Concat                    [1]                           \n",
            " 52                -1  1      4160  models.common.Conv                      [128, 32, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 53                -2  1      4160  models.common.Conv                      [128, 32, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 54                -1  1      9280  models.common.Conv                      [32, 32, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 55                -1  1      9280  models.common.Conv                      [32, 32, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 56  [-1, -2, -3, -4]  1         0  models.common.Concat                    [1]                           \n",
            " 57                -1  1      8320  models.common.Conv                      [128, 64, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 58                -1  1     73984  models.common.Conv                      [64, 128, 3, 2, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 59          [-1, 47]  1         0  models.common.Concat                    [1]                           \n",
            " 60                -1  1     16512  models.common.Conv                      [256, 64, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 61                -2  1     16512  models.common.Conv                      [256, 64, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 62                -1  1     36992  models.common.Conv                      [64, 64, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 63                -1  1     36992  models.common.Conv                      [64, 64, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 64  [-1, -2, -3, -4]  1         0  models.common.Concat                    [1]                           \n",
            " 65                -1  1     33024  models.common.Conv                      [256, 128, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 66                -1  1    295424  models.common.Conv                      [128, 256, 3, 2, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 67          [-1, 37]  1         0  models.common.Concat                    [1]                           \n",
            " 68                -1  1     65792  models.common.Conv                      [512, 128, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 69                -2  1     65792  models.common.Conv                      [512, 128, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 70                -1  1    147712  models.common.Conv                      [128, 128, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 71                -1  1    147712  models.common.Conv                      [128, 128, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 72  [-1, -2, -3, -4]  1         0  models.common.Concat                    [1]                           \n",
            " 73                -1  1    131584  models.common.Conv                      [512, 256, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 74                57  1     73984  models.common.Conv                      [64, 128, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 75                65  1    295424  models.common.Conv                      [128, 256, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 76                73  1   1180672  models.common.Conv                      [256, 512, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 77      [74, 75, 76]  1     68546  models.yolo.IDetect                     [20, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
            "/usr/local/lib/python3.7/dist-packages/torch/functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2894.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "Model Summary: 263 layers, 6066402 parameters, 6066402 gradients, 13.3 GFLOPS\n",
            "\n",
            "Transferred 330/344 items from yolov7-tiny.pt\n",
            "Scaled weight_decay = 0.0005\n",
            "Optimizer groups: 58 .bias, 58 conv.weight, 61 other\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/content/vegetadata/1.cache' images and labels... 1 found, 0 missing, 0 empty, 0 corrupted: 100% 1/1 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning '/content/vegetadata/1.cache' images and labels... 1 found, 0 missing, 0 empty, 0 corrupted: 100% 1/1 [00:00<?, ?it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 5.00, Best Possible Recall (BPR) = 1.0000\n",
            "Image sizes 640 train, 640 test\n",
            "Using 0 dataloader workers\n",
            "Logging results to runs/train/tinyModel5\n",
            "Starting training for 10 epochs...\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "       0/9     1.24G   0.05716   0.03607   0.04421    0.1374         3       640: 100% 1/1 [00:04<00:00,  4.31s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  1.03it/s]\n",
            "                 all           1           0           0           0           0           0\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "       1/9     1.28G   0.03705   0.03226    0.0133   0.08261         2       640: 100% 1/1 [00:00<00:00,  5.85it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00, 12.46it/s]\n",
            "                 all           1           0           0           0           0           0\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "       2/9     1.28G   0.05969   0.03445   0.03023    0.1244         1       640: 100% 1/1 [00:00<00:00,  5.43it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00, 12.07it/s]\n",
            "                 all           1           0           0           0           0           0\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "       3/9     1.28G   0.03749    0.0343  0.009878   0.08167         1       640: 100% 1/1 [00:00<00:00,  5.66it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00, 12.24it/s]\n",
            "                 all           1           0           0           0           0           0\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "       4/9     1.28G   0.02023   0.03446   0.01756   0.07225         1       640: 100% 1/1 [00:00<00:00,  5.85it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00, 12.50it/s]\n",
            "                 all           1           0           0           0           0           0\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "       5/9     1.28G   0.03217    0.0337   0.02109   0.08696         1       640: 100% 1/1 [00:00<00:00,  5.63it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00, 12.31it/s]\n",
            "                 all           1           0           0           0           0           0\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "       6/9     1.28G   0.02414   0.03427   0.02121   0.07962         2       640: 100% 1/1 [00:00<00:00,  5.93it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00, 11.64it/s]\n",
            "                 all           1           0           0           0           0           0\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "       7/9     1.28G   0.03382   0.03471   0.02206    0.0906         4       640: 100% 1/1 [00:00<00:00,  6.09it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00, 12.72it/s]\n",
            "                 all           1           0           0           0           0           0\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "       8/9     1.28G   0.05314   0.03527   0.04355     0.132         4       640: 100% 1/1 [00:00<00:00,  5.70it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00, 12.73it/s]\n",
            "                 all           1           0           0           0           0           0\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "       9/9     1.28G   0.05193   0.03323   0.04251    0.1277         2       640: 100% 1/1 [00:00<00:00,  5.84it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00, 10.29it/s]\n",
            "                 all           1           0           0           0           0           0\n",
            "10 epochs completed in 0.005 hours.\n",
            "\n",
            "Optimizer stripped from runs/train/tinyModel5/weights/last.pt, 12.4MB\n",
            "Optimizer stripped from runs/train/tinyModel5/weights/best.pt, 12.4MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "goLE9eJYGLoC",
        "outputId": "123c5376-5cfa-43d7-803a-5f321198b5ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "shutil.copy(\"/content/yolov7/runs/train/tinyModel5/weights/best.pt\",\"/content/drive/MyDrive\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "7E2xbBJRGYY9",
        "outputId": "ab917994-ca6a-404a-a95e-fd3023b3e1b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/best.pt'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/yolov7\n",
        "!python export.py --weights /content/yolov7/runs/train/tinyModel5/weights/best.pt --grid --end2end --simplify \\\n",
        "        --topk-all 100 --iou-thres 0.65 --conf-thres 0.35 --img-size 640 640 --max-wh 640"
      ],
      "metadata": {
        "id": "HWWkzNPfHhU3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/yolov7\n",
        "!python detect.py --weights runs/train/tinyModel4/weights/best.pt --conf 0.25 --img-size 640 --source /content/vegetadata/vegeta/vegeta_1.jpg"
      ],
      "metadata": {
        "id": "Q4fXkfvXI0Gw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "064db5bf-ed91-4dbe-a620-6e642e6a7d38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/yolov7\n",
            "Namespace(agnostic_nms=False, augment=False, classes=None, conf_thres=0.25, device='', exist_ok=False, img_size=640, iou_thres=0.45, name='exp', no_trace=False, nosave=False, project='runs/detect', save_conf=False, save_txt=False, source='/content/vegetadata/vegeta/vegeta_1.jpg', update=False, view_img=False, weights=['runs/train/tinyModel4/weights/best.pt'])\n",
            "YOLOR 🚀 v0.1-115-g072f76c torch 1.12.1+cu113 CUDA:0 (Tesla T4, 15109.75MB)\n",
            "\n",
            "Fusing layers... \n",
            "IDetect.fuse\n",
            "/usr/local/lib/python3.7/dist-packages/torch/functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2894.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "Model Summary: 208 layers, 6059010 parameters, 0 gradients, 13.2 GFLOPS\n",
            " Convert model to Traced-model... \n",
            " traced_script_module saved! \n",
            " model is traced! \n",
            "\n",
            "Done. (11.3ms) Inference, (0.4ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp4/vegeta_1.jpg\n",
            "Done. (0.131s)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# For another training"
      ],
      "metadata": {
        "id": "ItQXPmvFI06_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/yolov7\n",
        "python train.py --weights yolov7.pt --data \"data/coco.yaml\" --workers 4 --batch-size 4 --img 416 --cfg cfg/training/yolov7.yaml --name yolov7 --hyp data/hyp.scratch.p5.yaml"
      ],
      "metadata": {
        "id": "owQCeUS95UBv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Backup"
      ],
      "metadata": {
        "id": "sqW6duutMOYA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/yolov7\n",
        "!python detect.py --weights runs/train/tinyModel5/weights/best.pt --conf 0.25 --img-size 640 --source"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HlNNX_YnMdLK",
        "outputId": "6c2e4f54-c020-4785-dac7-bf5e195158b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/yolov7\n",
            "Namespace(agnostic_nms=False, augment=False, classes=None, conf_thres=0.25, device='', exist_ok=False, img_size=640, iou_thres=0.45, name='exp', no_trace=False, nosave=False, project='runs/detect', save_conf=False, save_txt=False, source='inference/images', update=False, view_img=False, weights=['runs/train/tinyModel5/weights/best.pt'])\n",
            "YOLOR 🚀 v0.1-115-g072f76c torch 1.12.1+cu113 CUDA:0 (Tesla T4, 15109.75MB)\n",
            "\n",
            "Fusing layers... \n",
            "IDetect.fuse\n",
            "/usr/local/lib/python3.7/dist-packages/torch/functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2894.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "Model Summary: 208 layers, 6059010 parameters, 0 gradients, 13.2 GFLOPS\n",
            " Convert model to Traced-model... \n",
            " traced_script_module saved! \n",
            " model is traced! \n",
            "\n",
            "1 sasuke, 1 zoro, Done. (7.0ms) Inference, (4.5ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp/bus.jpg\n",
            "Done. (7.2ms) Inference, (0.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp/horses.jpg\n",
            "Done. (7.1ms) Inference, (0.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp/image1.jpg\n",
            "1 vegito, 5 ichigos, Done. (8.5ms) Inference, (1.0ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp/image2.jpg\n",
            "Done. (9.1ms) Inference, (0.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp/image3.jpg\n",
            "Done. (6.7ms) Inference, (0.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp/zidane.jpg\n",
            "Done. (0.698s)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/yolov7\n",
        "!python detect.py --weights runs/train/tinyModel5/weights/best.pt --conf 0.25 --img-size 640"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e45a62c5-7c7d-4632-c52b-a8a16e1ab3d1",
        "id": "QCvFDNUgNYF0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/yolov7\n",
            "Namespace(agnostic_nms=False, augment=False, classes=None, conf_thres=0.25, device='', exist_ok=False, img_size=640, iou_thres=0.45, name='exp', no_trace=False, nosave=False, project='runs/detect', save_conf=False, save_txt=False, source='/content/vegetadata/vegeta', update=False, view_img=False, weights=['runs/train/tinyModel5/weights/best.pt'])\n",
            "YOLOR 🚀 v0.1-115-g072f76c torch 1.12.1+cu113 CUDA:0 (Tesla T4, 15109.75MB)\n",
            "\n",
            "Fusing layers... \n",
            "IDetect.fuse\n",
            "/usr/local/lib/python3.7/dist-packages/torch/functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2894.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "Model Summary: 208 layers, 6059010 parameters, 0 gradients, 13.2 GFLOPS\n",
            " Convert model to Traced-model... \n",
            " traced_script_module saved! \n",
            " model is traced! \n",
            "\n",
            "Done. (7.1ms) Inference, (0.3ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_1.jpg\n",
            "Done. (7.5ms) Inference, (0.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_10.jpg\n",
            "Done. (7.0ms) Inference, (0.6ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_100.jpg\n",
            "1 vegito, Done. (6.8ms) Inference, (1.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_101.jpg\n",
            "Done. (7.0ms) Inference, (0.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_102.jpg\n",
            "1 sasuke, Done. (6.8ms) Inference, (1.0ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_103.jpg\n",
            "Done. (7.5ms) Inference, (0.7ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_104.jpg\n",
            "Done. (7.8ms) Inference, (0.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_105.jpg\n",
            "Done. (6.1ms) Inference, (0.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_106.jpg\n",
            "Done. (7.9ms) Inference, (0.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_107.jpg\n",
            "Done. (6.9ms) Inference, (0.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_108.jpg\n",
            "Done. (6.4ms) Inference, (0.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_109.jpg\n",
            "Done. (6.8ms) Inference, (0.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_11.jpg\n",
            "Done. (6.1ms) Inference, (0.6ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_110.jpg\n",
            "Done. (7.1ms) Inference, (0.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_111.jpg\n",
            "Done. (9.8ms) Inference, (0.3ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_112.jpg\n",
            "Done. (6.8ms) Inference, (0.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_113.jpg\n",
            "Done. (7.1ms) Inference, (0.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_114.jpg\n",
            "Done. (6.3ms) Inference, (0.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_115.jpg\n",
            "Done. (5.9ms) Inference, (0.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_116.jpg\n",
            "Done. (6.7ms) Inference, (0.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_117.jpg\n",
            "Done. (7.1ms) Inference, (0.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_118.jpg\n",
            "5 usops, Done. (7.6ms) Inference, (0.9ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_119.jpg\n",
            "Done. (7.0ms) Inference, (0.3ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_12.jpg\n",
            "Done. (7.3ms) Inference, (0.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_120.jpg\n",
            "1 vegeta, Done. (6.2ms) Inference, (1.0ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_121.jpg\n",
            "Done. (6.7ms) Inference, (0.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_122.jpg\n",
            "Done. (8.1ms) Inference, (0.9ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_123.jpg\n",
            "Done. (7.3ms) Inference, (0.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_124.jpg\n",
            "1 vegeta, 1 hinata, Done. (9.1ms) Inference, (0.9ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_125.jpg\n",
            "Done. (6.9ms) Inference, (0.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_126.jpg\n",
            "Done. (7.0ms) Inference, (0.6ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_127.jpg\n",
            "Done. (6.7ms) Inference, (0.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_128.jpg\n",
            "Done. (7.0ms) Inference, (0.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_129.jpg\n",
            "Done. (6.4ms) Inference, (0.7ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_13.jpg\n",
            "1 naruto, Done. (6.8ms) Inference, (0.9ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_130.jpg\n",
            "Done. (6.8ms) Inference, (0.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_131.jpg\n",
            "1 ichigo, 2 narutos, Done. (6.2ms) Inference, (1.0ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_132.jpg\n",
            "Done. (7.2ms) Inference, (0.3ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_133.jpg\n",
            "5 ichigos, 2 sanjis, Done. (6.3ms) Inference, (1.0ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_134.jpg\n",
            "1 vegeta, Done. (7.1ms) Inference, (0.8ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_135.jpg\n",
            "Done. (6.0ms) Inference, (0.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_136.jpg\n",
            "2 sanjis, Done. (6.6ms) Inference, (1.0ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_137.jpg\n",
            "Done. (6.7ms) Inference, (0.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_138.jpg\n",
            "Done. (6.3ms) Inference, (0.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_139.jpg\n",
            "Done. (7.5ms) Inference, (0.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_14.jpg\n",
            "7 ichigos, 1 naruto, 13 gogetas, Done. (7.1ms) Inference, (0.9ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_140.jpg\n",
            "1 vegito, Done. (9.7ms) Inference, (1.4ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_141.jpg\n",
            "Done. (7.3ms) Inference, (0.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_142.jpg\n",
            "Done. (7.0ms) Inference, (0.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_143.jpg\n",
            "1 vegeta, 1 sasuke, Done. (6.5ms) Inference, (1.0ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_144.jpg\n",
            "Done. (8.0ms) Inference, (0.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_145.jpg\n",
            "Done. (6.9ms) Inference, (0.7ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_146.jpg\n",
            "Done. (6.6ms) Inference, (0.8ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_147.jpg\n",
            "Done. (7.0ms) Inference, (0.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_148.jpg\n",
            "Done. (7.2ms) Inference, (0.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_149.jpg\n",
            "Done. (7.2ms) Inference, (0.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_15.jpg\n",
            "1 zoro, Done. (6.1ms) Inference, (0.9ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_150.jpg\n",
            "Done. (7.0ms) Inference, (0.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_151.jpg\n",
            "4 vegetas, Done. (6.7ms) Inference, (1.0ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_152.jpg\n",
            "Done. (7.2ms) Inference, (0.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_153.jpg\n",
            "Done. (7.1ms) Inference, (0.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_154.jpg\n",
            "Done. (6.5ms) Inference, (0.3ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_155.jpg\n",
            "1 sasuke, 1 nami, Done. (7.6ms) Inference, (1.4ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_156.jpg\n",
            "Done. (7.2ms) Inference, (0.6ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_157.jpg\n",
            "7 ichigos, 1 naruto, 13 gogetas, Done. (6.4ms) Inference, (0.9ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_158.jpg\n",
            "Done. (6.3ms) Inference, (0.6ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_159.jpg\n",
            "Done. (7.0ms) Inference, (0.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_16.jpg\n",
            "Done. (8.2ms) Inference, (0.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_160.jpg\n",
            "Done. (6.9ms) Inference, (0.7ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_161.jpg\n",
            "Done. (8.8ms) Inference, (0.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_162.jpg\n",
            "1 ichigo, Done. (6.9ms) Inference, (1.0ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_163.jpg\n",
            "Done. (7.5ms) Inference, (0.7ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_164.jpg\n",
            "Done. (7.1ms) Inference, (0.6ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_165.jpg\n",
            "Done. (6.7ms) Inference, (0.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_166.jpg\n",
            "Done. (7.2ms) Inference, (0.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_167.jpg\n",
            "Done. (8.4ms) Inference, (0.9ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_168.jpg\n",
            "1 songoku, 1 ichigo, 1 sanji, Done. (6.5ms) Inference, (1.0ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_169.jpg\n",
            "Done. (6.4ms) Inference, (0.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_17.jpg\n",
            "Done. (11.0ms) Inference, (0.7ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_170.jpg\n",
            "Done. (6.8ms) Inference, (0.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_171.jpg\n",
            "Done. (6.5ms) Inference, (0.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_172.jpg\n",
            "Done. (9.8ms) Inference, (0.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_173.jpg\n",
            "Done. (6.2ms) Inference, (0.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_174.jpg\n",
            "Done. (6.2ms) Inference, (0.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_175.jpg\n",
            "Done. (6.9ms) Inference, (0.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_176.jpg\n",
            "Done. (7.4ms) Inference, (0.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_177.jpg\n",
            "1 naruto, Done. (6.7ms) Inference, (0.9ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_178.jpg\n",
            "Done. (6.9ms) Inference, (0.6ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_179.jpg\n",
            "Done. (7.2ms) Inference, (0.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_18.jpg\n",
            "Done. (6.9ms) Inference, (0.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_180.jpg\n",
            "Done. (6.3ms) Inference, (0.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_181.jpg\n",
            "Done. (6.8ms) Inference, (0.6ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_182.jpg\n",
            "Done. (7.7ms) Inference, (0.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_183.jpg\n",
            "Done. (7.1ms) Inference, (0.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_184.jpg\n",
            "Done. (6.5ms) Inference, (0.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_185.jpg\n",
            "Done. (6.5ms) Inference, (0.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_186.jpg\n",
            "Done. (7.0ms) Inference, (0.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_187.jpg\n",
            "Done. (10.1ms) Inference, (0.6ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_188.jpg\n",
            "4 ichigos, Done. (7.9ms) Inference, (1.3ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_189.jpg\n",
            "1 hinata, Done. (6.6ms) Inference, (0.9ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_19.jpg\n",
            "1 vegeta, Done. (6.5ms) Inference, (0.9ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_190.jpg\n",
            "Done. (6.2ms) Inference, (0.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_191.jpg\n",
            "Done. (6.8ms) Inference, (0.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_192.jpg\n",
            "1 vegeta, 1 itachi, Done. (7.1ms) Inference, (1.0ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_193.jpg\n",
            "Done. (5.9ms) Inference, (0.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_194.jpg\n",
            "Done. (6.7ms) Inference, (0.7ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_195.jpg\n",
            "Done. (6.8ms) Inference, (0.6ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_196.jpg\n",
            "Done. (7.3ms) Inference, (0.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_197.jpg\n",
            "1 luffy, 6 zoros, 1 sanji, Done. (6.5ms) Inference, (1.0ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_198.jpg\n",
            "Done. (6.9ms) Inference, (0.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_199.jpg\n",
            "1 vegeta, Done. (6.0ms) Inference, (0.9ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_2.jpg\n",
            "Done. (7.0ms) Inference, (0.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_20.jpg\n",
            "Done. (7.4ms) Inference, (0.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_200.jpg\n",
            "Done. (6.5ms) Inference, (0.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_21.jpg\n",
            "1 sasuke, 1 nami, Done. (7.1ms) Inference, (0.9ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_22.jpg\n",
            "Done. (6.6ms) Inference, (0.7ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_23.jpg\n",
            "Done. (8.2ms) Inference, (0.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_24.jpg\n",
            "Done. (8.2ms) Inference, (0.3ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_25.jpg\n",
            "Done. (7.0ms) Inference, (0.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_26.jpg\n",
            "Done. (6.9ms) Inference, (0.7ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_27.jpg\n",
            "Done. (7.1ms) Inference, (0.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_28.jpg\n",
            "Done. (6.7ms) Inference, (0.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_29.jpg\n",
            "Done. (6.6ms) Inference, (0.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_3.jpg\n",
            "3 vegetas, 2 sasukes, 3 namis, Done. (7.1ms) Inference, (0.9ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_30.jpg\n",
            "1 vegito, 2 ichigos, 4 narutos, 9 sasukes, 2 zoros, 3 namis, Done. (8.1ms) Inference, (1.0ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_31.jpg\n",
            "Done. (7.6ms) Inference, (0.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_32.jpg\n",
            "1 songoku, 1 vegito, 1 naruto, Done. (6.2ms) Inference, (0.9ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_33.jpg\n",
            "Done. (6.7ms) Inference, (0.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_34.jpg\n",
            "Done. (6.5ms) Inference, (0.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_35.jpg\n",
            "Done. (7.3ms) Inference, (0.6ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_36.jpg\n",
            "Done. (7.0ms) Inference, (0.8ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_37.jpg\n",
            "Done. (6.4ms) Inference, (0.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_38.jpg\n",
            "Done. (7.3ms) Inference, (0.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_39.jpg\n",
            "Done. (7.2ms) Inference, (0.8ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_4.jpg\n",
            "1 vegeta, Done. (6.7ms) Inference, (1.0ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_40.jpg\n",
            "Done. (6.8ms) Inference, (0.6ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_41.jpg\n",
            "Done. (7.8ms) Inference, (0.3ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_42.jpg\n",
            "Done. (7.1ms) Inference, (0.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_43.jpg\n",
            "Done. (6.9ms) Inference, (0.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_44.jpg\n",
            "1 ichigo, 4 vegetas, Done. (6.8ms) Inference, (0.9ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_45.jpg\n",
            "Done. (7.4ms) Inference, (0.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_46.jpg\n",
            "Done. (6.6ms) Inference, (0.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_47.jpg\n",
            "Done. (6.9ms) Inference, (0.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_48.jpg\n",
            "Done. (6.3ms) Inference, (0.7ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_49.jpg\n",
            "Done. (6.1ms) Inference, (0.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_5.jpg\n",
            "10 luffys, Done. (7.5ms) Inference, (1.0ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_50.jpg\n",
            "Done. (6.6ms) Inference, (0.6ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_51.jpg\n",
            "1 ichigo, 3 narutos, Done. (7.2ms) Inference, (1.0ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_52.jpg\n",
            "Done. (6.7ms) Inference, (0.6ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_53.jpg\n",
            "Done. (6.8ms) Inference, (0.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_54.jpg\n",
            "1 songoku, 1 vegito, 1 naruto, Done. (6.2ms) Inference, (1.0ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_55.jpg\n",
            "Done. (7.1ms) Inference, (0.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_56.jpg\n",
            "1 vegeta, 1 gogeta, Done. (6.9ms) Inference, (0.9ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_57.jpg\n",
            "Done. (6.8ms) Inference, (0.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_58.jpg\n",
            "Done. (7.0ms) Inference, (0.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_59.jpg\n",
            "Done. (7.1ms) Inference, (0.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_6.jpg\n",
            "1 vegito, Done. (7.4ms) Inference, (1.0ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_60.jpg\n",
            "Done. (6.9ms) Inference, (0.7ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_61.jpg\n",
            "Done. (6.0ms) Inference, (0.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_62.jpg\n",
            "Done. (9.6ms) Inference, (0.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_63.jpg\n",
            "2 zoros, Done. (7.3ms) Inference, (0.9ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_64.jpg\n",
            "Done. (7.8ms) Inference, (0.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_65.jpg\n",
            "Done. (7.5ms) Inference, (0.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_66.jpg\n",
            "1 vegito, 1 ichigo, 2 narutos, 1 vegeta, 1 hinata, Done. (6.3ms) Inference, (0.9ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_67.jpg\n",
            "Done. (8.6ms) Inference, (0.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_68.jpg\n",
            "Done. (6.2ms) Inference, (0.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_69.jpg\n",
            "Done. (6.1ms) Inference, (0.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_7.jpg\n",
            "2 ichigos, Done. (6.9ms) Inference, (0.9ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_70.jpg\n",
            "Done. (7.7ms) Inference, (0.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_71.jpg\n",
            "1 ichigo, Done. (7.4ms) Inference, (1.0ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_72.jpg\n",
            "Done. (6.5ms) Inference, (0.7ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_73.jpg\n",
            "3 luffys, 1 vegito, Done. (6.5ms) Inference, (0.9ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_74.jpg\n",
            "Done. (6.7ms) Inference, (0.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_75.jpg\n",
            "4 luffys, 6 gogetas, Done. (7.3ms) Inference, (0.9ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_76.jpg\n",
            "Done. (9.0ms) Inference, (0.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_77.jpg\n",
            "Done. (6.1ms) Inference, (0.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_78.jpg\n",
            "1 ichigo, Done. (6.7ms) Inference, (1.0ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_79.jpg\n",
            "Done. (7.0ms) Inference, (0.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_8.jpg\n",
            "Done. (7.8ms) Inference, (0.8ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_80.jpg\n",
            "Done. (6.9ms) Inference, (0.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_81.jpg\n",
            "Done. (6.6ms) Inference, (0.6ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_82.jpg\n",
            "Done. (6.4ms) Inference, (0.6ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_83.jpg\n",
            "Done. (6.2ms) Inference, (0.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_84.jpg\n",
            "Done. (7.6ms) Inference, (0.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_85.jpg\n",
            "Done. (6.8ms) Inference, (0.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_86.jpg\n",
            "2 gogetas, 2 namis, Done. (7.3ms) Inference, (1.0ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_87.jpg\n",
            "Done. (6.2ms) Inference, (0.6ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_88.jpg\n",
            "1 sanji, Done. (6.9ms) Inference, (0.9ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_89.jpg\n",
            "Done. (7.0ms) Inference, (0.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_9.jpg\n",
            "Done. (7.4ms) Inference, (0.6ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_90.jpg\n",
            "Done. (6.4ms) Inference, (0.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_91.jpg\n",
            "Done. (6.3ms) Inference, (0.3ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_92.jpg\n",
            "Done. (7.0ms) Inference, (0.6ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_93.jpg\n",
            "Done. (7.3ms) Inference, (0.7ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_94.jpg\n",
            "Done. (7.5ms) Inference, (0.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_95.jpg\n",
            "2 vegitos, Done. (6.9ms) Inference, (0.9ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_96.jpg\n",
            "1 zoro, 2 namis, Done. (6.1ms) Inference, (1.0ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_97.jpg\n",
            "Done. (6.6ms) Inference, (0.6ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_98.jpg\n",
            "4 vegitos, 2 sanjis, 1 nami, Done. (7.1ms) Inference, (0.9ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp2/vegeta_99.jpg\n",
            "Done. (21.090s)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RyJrCbONOEsF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "import time\n",
        "from pathlib import Path\n",
        "\n",
        "import cv2\n",
        "import torch\n",
        "import torch.backends.cudnn as cudnn\n",
        "from numpy import random\n",
        "import os\n",
        "\n",
        "from models.experimental import attempt_load\n",
        "from utils.datasets import LoadStreams, LoadImages\n",
        "from utils.general import check_img_size, check_requirements, check_imshow, non_max_suppression, apply_classifier, \\\n",
        "    scale_coords, xyxy2xywh, strip_optimizer, set_logging, increment_path\n",
        "from utils.plots import plot_one_box\n",
        "from utils.torch_utils import select_device, load_classifier, time_synchronized, TracedModel\n",
        "\n",
        "\n",
        "def detect(save_img=False):\n",
        "    source, weights, view_img, save_txt, imgsz, trace = opt.source, opt.weights, opt.view_img, opt.save_txt, opt.img_size, not opt.no_trace\n",
        "    save_img = not opt.nosave and not source.endswith('.txt')  # save inference images\n",
        "    webcam = source.isnumeric() or source.endswith('.txt') or source.lower().startswith(\n",
        "        ('rtsp://', 'rtmp://', 'http://', 'https://'))\n",
        "\n",
        "    # Directories\n",
        "    save_dir = Path(increment_path(Path(opt.project) / opt.name, exist_ok=opt.exist_ok))  # increment run\n",
        "    (save_dir / 'labels' if save_txt else save_dir).mkdir(parents=True, exist_ok=True)  # make dir\n",
        "\n",
        "    # Initialize\n",
        "    set_logging()\n",
        "    device = select_device(opt.device)\n",
        "    half = device.type != 'cpu'  # half precision only supported on CUDA\n",
        "\n",
        "    # Load model\n",
        "    model = attempt_load(weights, map_location=device)  # load FP32 model\n",
        "    stride = int(model.stride.max())  # model stride\n",
        "    imgsz = check_img_size(imgsz, s=stride)  # check img_size\n",
        "\n",
        "    if trace:\n",
        "        model = TracedModel(model, device, opt.img_size)\n",
        "\n",
        "    if half:\n",
        "        model.half()  # to FP16\n",
        "\n",
        "    # Second-stage classifier\n",
        "    classify = False\n",
        "    if classify:\n",
        "        modelc = load_classifier(name='resnet101', n=2)  # initialize\n",
        "        modelc.load_state_dict(torch.load('weights/resnet101.pt', map_location=device)['model']).to(device).eval()\n",
        "\n",
        "    # Set Dataloader\n",
        "    vid_path, vid_writer = None, None\n",
        "    if webcam:\n",
        "        view_img = check_imshow()\n",
        "        cudnn.benchmark = True  # set True to speed up constant image size inference\n",
        "        dataset = LoadStreams(source, img_size=imgsz, stride=stride)\n",
        "    else:\n",
        "        dataset = LoadImages(source, img_size=imgsz, stride=stride)\n",
        "\n",
        "    # Get names and colors\n",
        "    names = model.module.names if hasattr(model, 'module') else model.names\n",
        "    colors = [[random.randint(0, 255) for _ in range(3)] for _ in names]\n",
        "\n",
        "    # Run inference\n",
        "    if device.type != 'cpu':\n",
        "        model(torch.zeros(1, 3, imgsz, imgsz).to(device).type_as(next(model.parameters())))  # run once\n",
        "    old_img_w = old_img_h = imgsz\n",
        "    old_img_b = 1\n",
        "\n",
        "    t0 = time.time()\n",
        "    for path, img, im0s, vid_cap in dataset:\n",
        "        img = torch.from_numpy(img).to(device)\n",
        "        img = img.half() if half else img.float()  # uint8 to fp16/32\n",
        "        img /= 255.0  # 0 - 255 to 0.0 - 1.0\n",
        "        if img.ndimension() == 3:\n",
        "            img = img.unsqueeze(0)\n",
        "\n",
        "        # Warmup\n",
        "        if device.type != 'cpu' and (old_img_b != img.shape[0] or old_img_h != img.shape[2] or old_img_w != img.shape[3]):\n",
        "            old_img_b = img.shape[0]\n",
        "            old_img_h = img.shape[2]\n",
        "            old_img_w = img.shape[3]\n",
        "            for i in range(3):\n",
        "                model(img, augment=opt.augment)[0]\n",
        "\n",
        "        # Inference\n",
        "        t1 = time_synchronized()\n",
        "        with torch.no_grad():   # Calculating gradients would cause a GPU memory leak\n",
        "            pred = model(img, augment=opt.augment)[0]\n",
        "        t2 = time_synchronized()\n",
        "\n",
        "        # Apply NMS\n",
        "        pred = non_max_suppression(pred, opt.conf_thres, opt.iou_thres, classes=opt.classes, agnostic=opt.agnostic_nms)\n",
        "        t3 = time_synchronized()\n",
        "\n",
        "        # Apply Classifier\n",
        "        if classify:\n",
        "            pred = apply_classifier(pred, modelc, img, im0s)\n",
        "\n",
        "        # Process detections\n",
        "        for i, det in enumerate(pred):  # detections per image\n",
        "            if webcam:  # batch_size >= 1\n",
        "                p, s, im0, frame = path[i], '%g: ' % i, im0s[i].copy(), dataset.count\n",
        "            else:\n",
        "                p, s, im0, frame = path, '', im0s, getattr(dataset, 'frame', 0)\n",
        "\n",
        "            p = Path(p)  # to Path\n",
        "            save_path = str(save_dir / p.name)  # img.jpg\n",
        "            txt_path = str(save_dir / 'labels' / p.stem) + ('' if dataset.mode == 'image' else f'_{frame}')  # img.txt\n",
        "            gn = torch.tensor(im0.shape)[[1, 0, 1, 0]]  # normalization gain whwh\n",
        "            if len(det):\n",
        "                # Rescale boxes from img_size to im0 size\n",
        "                det[:, :4] = scale_coords(img.shape[2:], det[:, :4], im0.shape).round()\n",
        "\n",
        "                # Print results\n",
        "                for c in det[:, -1].unique():\n",
        "                    n = (det[:, -1] == c).sum()  # detections per class\n",
        "                    s += f\"{n} {names[int(c)]}{'s' * (n > 1)}, \"  # add to string\n",
        "\n",
        "                # Write results\n",
        "                for *xyxy, conf, cls in reversed(det):\n",
        "                    if save_txt:  # Write to file\n",
        "                        xywh = (xyxy2xywh(torch.tensor(xyxy).view(1, 4)) / gn).view(-1).tolist()  # normalized xywh\n",
        "                        line = (cls, *xywh, conf) if opt.save_conf else (cls, *xywh)  # label format\n",
        "                        with open(txt_path + '.txt', 'a') as f:\n",
        "                            f.write(('%g ' * len(line)).rstrip() % line + '\\n')\n",
        "\n",
        "                    if save_img or view_img:  # Add bbox to image\n",
        "                        label = f'{names[int(cls)]} {conf:.2f}'\n",
        "                        plot_one_box(xyxy, im0, label=label, color=colors[int(cls)], line_thickness=1)\n",
        "\n",
        "            # Print time (inference + NMS)\n",
        "            print(f'{s}Done. ({(1E3 * (t2 - t1)):.1f}ms) Inference, ({(1E3 * (t3 - t2)):.1f}ms) NMS')\n",
        "\n",
        "            # Stream results\n",
        "            if view_img:\n",
        "                cv2.imshow(str(p), im0)\n",
        "                cv2.waitKey(1)  # 1 millisecond\n",
        "\n",
        "            # Save results (image with detections)\n",
        "            if save_img:\n",
        "                if dataset.mode == 'image':\n",
        "                    cv2.imwrite(save_path, im0)\n",
        "                    print(f\" The image with the result is saved in: {save_path}\")\n",
        "                else:  # 'video' or 'stream'\n",
        "                    if vid_path != save_path:  # new video\n",
        "                        vid_path = save_path\n",
        "                        if isinstance(vid_writer, cv2.VideoWriter):\n",
        "                            vid_writer.release()  # release previous video writer\n",
        "                        if vid_cap:  # video\n",
        "                            fps = vid_cap.get(cv2.CAP_PROP_FPS)\n",
        "                            w = int(vid_cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "                            h = int(vid_cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "                        else:  # stream\n",
        "                            fps, w, h = 30, im0.shape[1], im0.shape[0]\n",
        "                            save_path += '.mp4'\n",
        "                        vid_writer = cv2.VideoWriter(save_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (w, h))\n",
        "                    vid_writer.write(im0)\n",
        "\n",
        "    if save_txt or save_img:\n",
        "        s = f\"\\n{len(list(save_dir.glob('labels/*.txt')))} labels saved to {save_dir / 'labels'}\" if save_txt else ''\n",
        "        #print(f\"Results saved to {save_dir}{s}\")\n",
        "\n",
        "    print(f'Done. ({time.time() - t0:.3f}s)')\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    path=\"/content/vegetadata/vegeta\"\n",
        "    lst=os.listdir(path)\n",
        "    for i in lst:\n",
        "        parser = argparse.ArgumentParser()\n",
        "        parser.add_argument('--weights', nargs='+', type=str, default='yolov7.pt', help='model.pt path(s)')\n",
        "        parser.add_argument('--source', type=str, default=path+i, help='source')  # file/folder, 0 for webcam\n",
        "        parser.add_argument('--img-size', type=int, default=640, help='inference size (pixels)')\n",
        "        parser.add_argument('--conf-thres', type=float, default=0.35, help='object confidence threshold')\n",
        "        parser.add_argument('--iou-thres', type=float, default=0.65, help='IOU threshold for NMS')\n",
        "        parser.add_argument('--device', default='', help='cuda device, i.e. 0 or 0,1,2,3 or cpu')\n",
        "        parser.add_argument('--view-img', action='store_true', help='display results')\n",
        "        parser.add_argument('--save-txt', action='store_true', help='save results to *.txt')\n",
        "        parser.add_argument('--save-conf', action='store_true', help='save confidences in --save-txt labels')\n",
        "        parser.add_argument('--nosave', action='store_true', help='do not save images/videos')\n",
        "        parser.add_argument('--classes', nargs='+', type=int, help='filter by class: --class 0, or --class 0 2 3')\n",
        "        parser.add_argument('--agnostic-nms', action='store_true', help='class-agnostic NMS')\n",
        "        parser.add_argument('--augment', action='store_true', help='augmented inference')\n",
        "        parser.add_argument('--update', action='store_true', help='update all models')\n",
        "        parser.add_argument('--project', default='runs/detect', help='save results to project/name')\n",
        "        parser.add_argument('--name', default='exp', help='save results to project/name')\n",
        "        parser.add_argument('--exist-ok', action='store_true', help='existing project/name ok, do not increment')\n",
        "        parser.add_argument('--no-trace', action='store_true', help='don`t trace model')\n",
        "\n",
        "        opt = parser.parse_args()\n",
        "        print(opt)\n",
        "        #check_requirements(exclude=('pycocotools', 'thop'))\n",
        "\n",
        "        with torch.no_grad():\n",
        "            if opt.update:  # update all models (to fix SourceChangeWarning)\n",
        "                for opt.weights in ['yolov7.pt']:\n",
        "                    detect()\n",
        "                    strip_optimizer(opt.weights)\n",
        "            else:\n",
        "                detect()\n"
      ],
      "metadata": {
        "id": "neOhozATLKoi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}